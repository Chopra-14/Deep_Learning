import tensorflow as tf
from tensorflow.keras import layers, datasets, preprocessing, Sequential
import numpy as np
# Load data
vocab_size = 10000
maxlen = 200
(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocab_size)
# Pad sequences
x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)
# Build RNN model
model = Sequential([
    layers.Embedding(vocab_size, 64, input_length=maxlen),
    layers.SimpleRNN(64),
    layers.Dense(1, activation='sigmoid')
])
# Compile and train
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2, verbose=1)
# Evaluate
loss, acc = model.evaluate(x_test, y_test, verbose=2)
print("Test Accuracy:", acc)
